---
title: "2_Analysis_create matrices"
author: "Annemarie van der Marel"
date: "2024-09-06"
output: html_document
---


# load libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# data cleaning etc
library(tidyverse)
library(job) # to run models in the background
library(igraph)
```

# import data

```{r}
scan_raw <- read.csv("../data/2024/2024_scan_cleaned_final.csv") %>% 
  rename(scanid=scansid) 
unique(scan_raw$actor)
behave_raw <- read.csv("../data/2024/2024_interactions_cleaned_final.csv")

# degus <- read.csv("./data/2024/degusID24.csv") %>% 
#   filter(select==1)
degus <- read.csv("../data/2024/2024_alldegustrapped.csv") 

locations_raw <- read.csv("../data/2024/el roble burrow locations.csv") %>% 
  janitor::clean_names() 

idchars24 <- read.csv("../results/idcharacteristics24_nogroup.csv")

```

# Helper functions & data
```{r echo=FALSE}

#make matrix function (from dataframe, 1st col with row names)
matrix.please<-function(x) {
  m<-as.matrix(x[,-1])
  rownames(m)<-x[,1]
  m
}

# list of degus
degulist <- degus %>%
  filter(age=="A") %>%
  dplyr::select(id)
adultdegus <- sort(unique(degulist$id)) 

id.sex <- degus %>%
  filter(age=="A") %>%
  dplyr::select(id,  sex) 
```

##locations
```{r}
range(locations_raw$date)
range(locations_raw$burrow_or_other)

locations <- locations_raw %>% 
  group_by(burrow_or_other) %>% 
  summarize(easting_x = round(mean(x_west_to_east, digits = 0)),
            northing_y = mean(y_south_to_north))  %>%
  filter(!is.na(easting_x)) %>%
  rename(location=burrow_or_other)

unique(levels(as.factor(scan_raw$location)))
unique(levels(as.factor(locations$location)))

locations$location[locations$location=="ANDAMIO E 2022"] <- "t2"
locations$location[locations$location=="ANDAMIO W 2022"] <- "t3"
locations$location[locations$location=="10m N36"] <- "rp"  # rp 10m N36

#10m NE36  = location 36, meter 10, direction "ne"
# tz = trap zone = 33 10 w
# a1 and z3?
```

# get data ready
## dates

```{r}
fall <- seq(as.Date("2024-06-06"), as.Date("2024-08-22"), by="days") 
                                                                                                                        
```





```{r}
scan <- scan_raw %>% 
  filter(date %in% fall) 
unique(scan$date)
length(unique(scan$date))

behave <- behave_raw %>% 
   filter(date %in% fall)
unique(behave$date)
length(unique(behave$date)) 


```

##hours observed

```{r}
# fall
length(unique(scan$date)) 
length(unique(scan$scanid)) 
max(scan$scanid) 
totalhoursobs <- length(unique(scan$scanid)) / 6 # each scan is 10 minutes, so 6 scans per hour
avgtimedaily <- totalhoursobs/40 # 4.5 hours/daily


```

##select degus seen on at least 5 days and at least 5 scans


```{r select degus}
scansummary <- scan %>%
  group_by(actor) %>%
  summarize(nscans_act=n_distinct(scanid), 
            ndays_act=n_distinct(julian_date)) %>% 
  rename(id=actor)
  

scansummary_subject <- scan %>%
  group_by(subject) %>%
  summarize(nscans_sub=n_distinct(scanid), 
            ndays_sub=n_distinct(julian_date))%>% 
  rename(id=subject)
  

scansummtotal <- scansummary %>% 
  left_join(scansummary_subject) %>% 
  replace(is.na(.), 0) %>% 
  mutate(nscans=nscans_act+nscans_sub,
         ndays=ndays_act +ndays_sub)


remove.ids <- scansummtotal %>%
  filter(ndays<6 ) %>% 
  dplyr::select(id)

remove.ids <- remove.ids$id
exclude_ids <- c("untagged", "unmarked", "summer juvenile", "juvenile", "unknown female", "unknown female ",
                 "male summer juvenile", "male summer juvenile 16",  
                 "unknown", "offspring", "red rectangle", "red roman 1",
                 "unmarked with crooked tail", "abracoma","red open circle on back" )

scan_analyses <- scan %>%
  filter(!actor %in% remove.ids, 
         !subject %in% remove.ids, 
         !actor %in% exclude_ids, 
         !subject %in% exclude_ids,
         actor %in% adultdegus)
         #subject %in% adultdegus ) # keep only observations where the actor is in the list of bird IDs 
        
length(unique(scan_analyses$actor))
sort(unique(scan_analyses$actor))
```


## observation bias
```{r observation bias}
hours.obs <- scan_analyses %>%                 
  group_by(actor) %>%
  summarise(scans=n_distinct(scanid), hours.obs=scans/6) 

```

## dyad list with observed degus
```{r dyad list}
# list of all possible dyads
# selectdegus <- filter(degulist,
#                       !id %in% remove.ids,
#                       !id %in% exclude_ids,
#                       id %in% adultdegus)
#                       #id %in% trappeddegus)

selectdegus <- scansummtotal %>%
  filter(ndays>5, id %in% adultdegus) %>% 
  dplyr::select(id)
id<-selectdegus$id

dyad.list <- expand.grid(selectdegus$id, selectdegus$id) #head(dyad.list)
names(dyad.list) <- c("actor", "subject")
dyad.list <- subset(dyad.list, actor!=subject)
#dyad.list$dyadID <- paste(dyad.list$actor, dyad.list$subject, sep="-")

dyad.list$actor <- as.factor(dyad.list$actor)
dyad.list$subject <- as.factor(dyad.list$subject)
```


##behave ids

```{r}


behavesummary <- behave %>%
  group_by(actor) %>%
  summarize( 
            ndays=n_distinct(julian_date))

behave_analyses <- behave %>%
   filter(actor %in% id, 
          subject %in% id)
# 
# behave_analyses <- behave %>%
#   filter(!actor %in% remove.ids, 
#          !subject %in% remove.ids, 
#          !actor %in% exclude_ids, 
#          !subject %in% exclude_ids,
#          actor %in% adultdegus, # keep only observations where the actor is in the list of bird IDs 
#          subject %in% adultdegus,
#          actor %in% trappeddegus, # only keep individuals with at least a measure of body condition, meaning that they were trapped
#          subject %in% trappeddegus)

length(unique(levels(as.factor(behave_analyses$actor))))
unique(behave_analyses$subject)
```





# Proximity


## from locations during scans
Throughout the day, patterns of group formation and sexual segregation might differ from those present at night (Radespiel etÂ al. 2001). We therefore also calculated the mean percentage of adult males and females in a 3-m radius within a 10-min scan using all our scan samples.



```{r fall}
range(scan_analyses$date)

scan_locs <- scan_analyses %>% 
  left_join(locations, by = "location")

```

add meters and wind direction to easting and northing

```{r meters to UTM easting and northing}

# ifelse(condition, do_if_true, do_if_false)
# ifelse(test, result1, ifelse(test2, result2, result3))

h<-scan_locs %>%
  rename(coordinates=meter)

levels(as.factor(scan_locs$direction))

### only east and north

# h$newx <- ifelse(h$direction=="e", h$coordinates + h$easting_x,
#                  ifelse(h$direction=="w", h$easting_x-h$coordinates, h$easting_x))
# h$newy<- ifelse(h$direction=="N", h$coordinates + h$northing_y,
#                 ifelse(h$direction=="S", h$northing_y-h$coordinates, h$northing_y))

### all
# if east add meters to easting (x)
# if west substract meters from easting (x)
# if north add meters to northing (y)
# if south substract meters to northing (y)
# if direction = NE, then add (coordinates*sin45)/sin90 to easting(x) &
#                   add (coordinates*sin45)/sin90 to northing (y)
# if direction = SE, then add (coordinates*sin45)/sin90 to easting(x) &
#                   subtract (coordinates*sin45)/sin90 from northing (y)
# if direction = SW, then subtract (coordinates*sin45)/sin90 from easting(x) &
#                   subtract (coordinates*sin45)/sin90 from northing (y)
# if direction = NW, then subtract (coordinates*sin45)/sin90 from easting(x) &
#                   add (coordinates*sin45)/sin90 to northing (y)
h$x<-ifelse(is.na(h$direction), h$easting_x,
      ifelse(h$direction=="e", h$coordinates + h$easting_x,
         ifelse(h$direction=="w", h$easting_x-h$coordinates,
            ifelse(h$direction=="ne",h$easting_x + ((h$coordinates*sin(45))/sin(90)),
               ifelse(h$direction=="se",h$easting_x + ((h$coordinates*sin(45))/sin(90)),
                  ifelse(h$direction=="sw",h$easting_x - ((h$coordinates*sin(45))/sin(90)),
                     ifelse(h$direction=="nw",h$easting_x - ((h$coordinates*sin(45))/sin(90)),h$easting_x)))))))

h$y<-ifelse(is.na(h$direction), h$northing_y,
      ifelse(h$direction=="n", h$coordinates + h$northing_y,
        ifelse(h$direction=="s", h$northing_y-h$coordinates,
           ifelse(h$direction=="ne",h$northing_y + ((h$coordinates*sin(45))/sin(90)),
            ifelse(h$direction=="se",h$northing_y - ((h$coordinates*sin(45))/sin(90)),
               ifelse(h$direction=="sw",h$northing_y - ((h$coordinates*sin(45))/sin(90)),
                ifelse(h$direction=="nw",h$northing_y + ((h$coordinates*sin(45))/sin(90)),h$northing_y)))))))


glimpse(h)
#View(h)

scan_prox <- h %>% 
  select(-easting_x, -northing_y)
```



Using spatsoc, I have to exclude multiple instances of the same degu per scan

```{r}
prox_degus <- scan_prox %>% 
  select(orderkey, scanid, actor) %>% 
  group_by(scanid,  actor) %>% 
  tally() 

scan_1xdegus <- scan_prox %>% 
  #select(orderkey, scanid, actor) %>% 
  group_by(scanid,  actor) %>% 
  slice(1) %>% 
  arrange(orderkey) 
```


Now per scan, we want to measure who is within 3 m of one another

a(x1,y1) 
b(x2,y2)
what is the distance between the 2 points? 

d = sqrt((x2-x1)^2 +(y2-y1)^2

```{r}
#library("sf)

#raster::pointDistance()
# distance <- scan_prox %>%
#   filter(scanid==1) %>% 
#   summarize(distance=  raster::pointDistance(cbind(x, y),
#                                cbind(lag(x), lag(y)),
#                                lonlat = FALSE,
#                                allpairs = FALSE))
  
#library("spatsoc")
dist = data.table::setDT(scan_1xdegus)

distance <- spatsoc::group_pts(DT = dist, 
                   threshold = 2, 
                   id='actor',
                   coords = c("x", "y"),
                   timegroup = 'scanid')

# only keep instances where more than 1 degus was observed
distance_select <- distance %>% 
  group_by(group) %>% 
  tally() %>% 
  filter(n>1) # 4 degus within 2 m is the largest 'group'
max(distance_select$n)

prox_groups <- distance   %>% 
  filter(group %in% distance_select$group) %>% # long format
  rename(meter=coordinates)


# change to wide format: 
prox_groups_wide <- prox_groups %>% 
  filter(actor %in% adultdegus) %>% 
  group_by(group) %>%
  #mutate(dyad= combn(actor, 2, simplify=FALSE))
  mutate(group_members = paste(actor,collapse = "_")) %>%    
  dplyr::select(scanid, julian_date, group, group_members) %>% 
  group_by(group) %>% slice(1) %>%
  separate(group_members,into = c("id1","id2","id3","id4", "id5", "id6"),sep = "_") 



  
```

https://stackoverflow.com/questions/69171494/how-to-create-an-edgelist-from-a-dataframe-expand-group-by
```{r observed proximity network}
# go from ids/group to dyads/group # maybe davidakenny.net/RDDD.htm
# dyad<-if(groups$groupID==groups$groupID+1,unite(dyads,ids, sep = "_"),NA )
# dyad<-group_by(groups, groupID) %>%   transmute(dyads=unite(ids, sep = "_"))

# prox_locXdyad <- do.call("rbind", lapply(split(prox_groups, prox_groups$group), function(d) {
#    if (nrow(d) > 1) unique(do.call("rbind", combn(d$actor, 2, simplify = FALSE)))
# }))

prox_list <- do.call(
  rbind,
  lapply(
    with(prox_groups, split(actor, group)),
    function(v) {
      make_full_graph(length(v)) %>%
        set_vertex_attr(name = "name", value = v) %>%
        get.data.frame()
    }
  )
)


prox_locXdyad <- prox_list %>% 
  rename(id1=from, 
         id2=to) %>% 
  group_by(id1, id2) %>% 
  tally()




```


### from behaviors
Only proximity behaviors
```{r fall}
prox_behaviors <- levels(as.factor(behave_analyses$behavior[behave_analyses$behaviortypesid==1]))


prox <-  behave_analyses %>%
  filter(behaviortypesid==1, 
         actor!=subject) # 1994 observations of proximity behaviors, seems to all be part of the scans as well
```

Now check whether we have duplicates from the location datafame

```{r}

prox_duplicates <- prox %>% 
  select(-orderkey) %>% 
  semi_join(select(prox_groups, -orderkey), 
            by=c("actor", "sex_actor","behavior", "subject", "sex_subject", 
                 "location", "meter", "direction", "date", "julian_date", 
                  "year", "month", "day", "time", "duration"))  # 337 duplicates/17 dyuplicates

# remove these from the behavior dataframe

prox_behave <- prox %>% 
  anti_join(prox_duplicates)

head(prox_behave)

# check
length(prox$orderkey)-length(prox_behave$orderkey)==length(prox_duplicates$session_key)
```

Summarize so that we can join the 2 dataframes as now we have the interaction and the scan dataset. 

```{r fall}
prox_behaveXdyad <- behave_analyses %>%
  filter(behaviortypesid==1, 
         actor!=subject) %>%
  group_by(actor, subject) %>%
  tally() %>% 
  rename(id1=actor,
         id2=subject)
```



### combine

combine proximity interaction and scan location dataframes
```{r}

prox_combine <- full_join(prox_behaveXdyad, prox_locXdyad, 
                          by=c("id1", "id2"))

prox_combine[is.na(prox_combine)]<-0

proxXdyad <- prox_combine %>% 
  mutate(n=n.x+n.y) %>% 
  rename(n_behave=n.x, 
         n_scan=n.y) %>% 
  select(id1, id2, n, everything())

total.prox<- sum(proxXdyad $n)

proxXdyad $id1 <- as.factor(proxXdyad$id1)
proxXdyad $id2 <- as.factor(proxXdyad$id2)


# control for observation bias
# fall
hours.obs.id <- hours.obs %>%
  rename(id1=actor)

prxXdyad.c <- proxXdyad %>% 
  left_join(hours.obs.id, by="id1") %>% 
  select( -scans) %>% 
  rename(actor.obs=hours.obs)
hours.obs.s<-select(hours.obs.id, -scans) %>% 
  rename(id2=id1,
    subject.obs=hours.obs)

proxXdyad.control <-prxXdyad.c  %>% 
  left_join(hours.obs.s, by="id2") %>% 
  mutate(ave.obs=(actor.obs+subject.obs)/2, 
         frequency=n/ave.obs) 



# include all degus
 n_distinct(dyad.list$actor)
  n_distinct(dyad.list$subject)

  dyad.prox.list <- dyad.list %>% 
  rename(id1=actor, 
         id2=subject)
dyad.prox.list$id1 <- as.factor(dyad.prox.list$id1)
dyad.prox.list$id2 <- as.factor(dyad.prox.list$id2)

prox_alldyads <- full_join(dyad.prox.list , proxXdyad.control ) 

  #head(data_alldyads)
  #length(unique(data_alldyads$dyadID)) # with 95 degus should be 8930 dyads
  
 #fill newly-merged data with 0's where no interactions
 prox_alldyads[is.na(prox_alldyads)] <- 0
 
 n_distinct(prox_alldyads$id1)
  n_distinct(prox_alldyads$id2)
  
   #print a check
  check <- length(prox_alldyads$id1)
```

NB! If I want to select a certain time period, I'll have to rerun the analyses and make my selection at the start.
### save file
```{r}
# final
write.csv(prox_alldyads, "results/proximity_alldyads_fall24.csv") 
write.csv(proxXdyad.control, "results/proximityXdyad_fall24.csv") 


```



## Affiliative interactions

Check whether the metrics work on fractions instead of integers. 


```{r affiliative network}

cat_check <- behave_analyses %>%
  filter(behaviortypesid==2)
unique(cat_check$behavior)


affXdyad <- behave_analyses %>%
  filter(behaviortypesid==2, actor!=subject) %>% 
  group_by(actor, subject) %>%
  tally()
affXdyad$actor <- as.factor(affXdyad$actor)
affXdyad$subject <- as.factor(affXdyad$subject)


total.aff <- sum(affXdyad$n)


# control for observation bias
affXdyad.c <- affXdyad %>% 
  left_join(hours.obs, by="actor") %>% 
  select( -scans) %>% 
  rename(actor.obs=hours.obs)
hours.obs.s<-select(hours.obs, -scans) %>% 
  rename(subject=actor,
    subject.obs=hours.obs)

affXdyad.control <-affXdyad.c  %>% 
  left_join(hours.obs.s, by="subject") %>% 
  mutate(ave.obs=(actor.obs+subject.obs)/2, 
         frequency=n/ave.obs) 

# include all ID's

 aff_alldyads <- full_join(dyad.list, affXdyad.control) #dyad.list when all 113 degus

 #fill newly-merged data with 0's where no interactions
 aff_alldyads[is.na(aff_alldyads)] <- 0

 
    #print a check
  check <- length(aff_alldyads$actor)
   sum(aff_alldyads$n) 

aff_alldyads <- aff_alldyads %>%
  rename(id1=actor, id2=subject)

n_distinct(aff_alldyads$id1)
  n_distinct(aff_alldyads$id2)


  
# save file
write.csv(aff_alldyads, "results/affiliative_alldyads_fall24.csv")
write.csv(affXdyad.control, "results/affiliativeXdyad_fall24.csv")

```

## Agonistic interactions
```{r agonistic network + dominance}

cat_check <- behave_analyses %>%
  filter(behaviortypesid==3)
unique(cat_check$behavior)


aggXdyad <- behave_analyses %>%
  filter(behaviortypesid==3, actor!=subject) %>% 
  group_by(actor, subject) %>%
  tally()

total.agg <- sum(aggXdyad$n)


# control for observation bias
aggXdyad.c <- aggXdyad %>% 
  left_join(hours.obs, by="actor") %>% 
  select( -scans) %>% 
  rename(actor.obs=hours.obs)
hours.obs.s<-select(hours.obs, -scans) %>% 
  rename(subject=actor,
    subject.obs=hours.obs)

aggXdyad.control <-aggXdyad.c  %>% 
  left_join(hours.obs.s, by="subject") %>% 
  mutate(ave.obs=(actor.obs+subject.obs)/2, 
         frequency=n/ave.obs) 



head(aggXdyad)

 ag_alldyads <- full_join(dyad.list, aggXdyad.control) # dyad list for all 113 degus
 #merge(dyad.list, agg, all.x=TRUE, by=c("actor", "subject")) 
  
  #head(data_alldyads)
  #length(unique(data_alldyads$dyadID)) # with 95 degus should be 8930 dyads
  
 #fill newly-merged data with 0's where no interactions
 ag_alldyads[is.na(ag_alldyads)] <- 0
  
   #print a check
  check <- length(ag_alldyads$actor)
sum(ag_alldyads$n)

ag_alldyads <- ag_alldyads %>%
  rename(id1=actor, id2=subject)

n_distinct(ag_alldyads$id1)
  n_distinct(ag_alldyads$id2)

# save file
write.csv(aggXdyad.control, "../results/agonisticXdyad_fall24.csv")  
write.csv(ag_alldyads, "../results/agonistic_alldyads_fall24.csv")
```






